name = 'PyTorch'
version = '1.12.0'

homepage = 'https://pytorch.org/'
description = """Tensors and Dynamic neural networks in Python with strong GPU acceleration.
PyTorch is a deep learning framework that puts Python first."""

toolchain = {'name': 'foss', 'version': '2022a'}

source_urls = [GITHUB_RELEASE]
sources = ['%(namelower)s-v%(version)s.tar.gz']
patches = [
    '%(name)s-1.7.0_avoid-nan-in-test-torch.patch',
    '%(name)s-1.7.0_disable-dev-shm-test.patch',
    '%(name)s-1.9.0_limit-world-size-for-zero-redundancy-opt-test.patch',
    '%(name)s-1.10.0_fix-test-dataloader-fixed-affinity.patch',
    '%(name)s-1.10.0_skip_cmake_rpath.patch',
    '%(name)s-1.11.0_increase-distributed-test-timeout.patch',
    '%(name)s-1.11.0_increase_c10d_gloo_timeout.patch',
    '%(name)s-1.11.0_disable_failing_jit_cuda_fuser_tests.patch',
]
checksums = [
    {'%(namelower)s-v1.12.0.tar.gz': '46eff236370b759c427b03ff535c3597099043e8e467b8f81f9cd4b258a7a321'},
    {'%(name)s-1.7.0_avoid-nan-in-test-torch.patch': 'b899aa94d9e60f11ee75a706563312ccefa9cf432756c470caa8e623991c8f18'},
    {'%(name)s-1.7.0_disable-dev-shm-test.patch': '622cb1eaeadc06e13128a862d9946bcc1f1edd3d02b259c56a9aecc4d5406b8a'},
    {'%(name)s-1.9.0_limit-world-size-for-zero-redundancy-opt-test.patch': 'ff573660913ce055e24cfd194ce747ba5685091c631cfd443eae2a99d56b57ea'},
    {'%(name)s-1.10.0_fix-test-dataloader-fixed-affinity.patch': '313dca681f45ce3bc7c4557fdcdcbe0b77216d2c708fa30a2ec0e22c44876707'},
    {'%(name)s-1.10.0_skip_cmake_rpath.patch': 'ac05943bb205623f91ef140aa00869efc5fe844184bd666bebf5405808610448'},
    {'%(name)s-1.11.0_increase-distributed-test-timeout.patch': '087ad20163a1291773ae3457569b80523080eb3731e210946459b2333a919f3f'},
    {'%(name)s-1.11.0_increase_c10d_gloo_timeout.patch': '20cd4a8663f74ab326fdb032b926bf5c7e94d9750c515ab9050927ba00cf1953'},
    {'%(name)s-1.11.0_disable_failing_jit_cuda_fuser_tests.patch': 'e7bfe120a8b3fe2b40dac6839852a5fbab3cb3429fbe44a0fc3a1800adaaee51'},
]

builddependencies = [
    ('CMake', '3.23.1', '', ('GCCcore', '11.3.0')),
    ('hypothesis', '6.46.7', '', ('GCCcore', '11.3.0')),
]
dependencies = [
    ('Ninja', '1.10.2', '', ('GCCcore', '11.3.0')),
    ('Python', '3.10.4', '', ('GCCcore', '11.3.0')),
    ('protobuf', '3.19.4', '', ('GCCcore', '11.3.0')),
    ('protobuf-python', '3.19.4', '', ('GCCcore', '11.3.0')),
    ('pybind11', '2.9.2', '', ('GCCcore', '11.3.0')),
    ('SciPy-bundle', '2022.05'),
    ('PyYAML', '6.0', '', ('GCCcore', '11.3.0')),
    ('MPFR', '4.1.0', '', ('GCCcore', '11.3.0')),
    ('GMP', '6.2.1', '', ('GCCcore', '11.3.0')),
    ('numactl', '2.0.14', '', ('GCCcore', '11.3.0')),
    ('FFmpeg', '4.4.2', '', ('GCCcore', '11.3.0')),
    ('Pillow', '9.1.1', '', ('GCCcore', '11.3.0')),
    ('expecttest', '0.1.3', '', ('GCCcore', '11.3.0')),
]

osdependencies = [('libibverbs-dev', 'libibverbs-devel', 'rdma-core-devel')]

runtest = "cd test && PYTHONUNBUFFERED=1 %(python)s run_test.py --continue-through-error  --verbose %(excluded_tests)s"
tests = ['%(name)s-check-cpp-extension.py']
excluded_tests = {
    '': ['distributed/elastic/utils/distributed_test', 'distributed/elastic/multiprocessing/api_test', 'distributed/test_distributed_spawn', 'test_optim', 'test_model_dump', 'distributed/fsdp/test_fsdp_memory', 'distributed/fsdp/test_fsdp_overlap'],
}
# several tests are known to be flaky, and fail in some contexts (like having multiple GPUs available),
# so we allow up to 400 (out of ~90k) tests to fail before treating the installation to be faulty
max_failed_tests = 400

moduleclass = 'ai'
